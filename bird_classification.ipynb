{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAnjMHYtuFTg"
      },
      "source": [
        "# Importing data and Google Drive Mount"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ekNOG9Aels8X"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oLHdtoewqEVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ea7f01-6116-4b9c-cded-edf528a88ce8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vppNstoNuNzb"
      },
      "source": [
        "# Importing Stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30oHr38Ft1BR"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os,pickle\n",
        "import numpy as np\n",
        "from  tqdm import tqdm\n",
        "import librosa\n",
        "import librosa.display\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "RVtpFT9IrnI3",
        "outputId": "dd1ed75f-254f-42d7-9ce7-ee57fb1ca387"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   file_id         genus    species   english_cname who_provided_recording  \\\n",
              "0   132608      Acanthis    flammea  Common Redpoll         Jarek Matusiak   \n",
              "1   132611      Acanthis    flammea  Common Redpoll         Jarek Matusiak   \n",
              "2    35068      Acanthis    flammea  Common Redpoll             Sander Bot   \n",
              "3    82715  Acrocephalus  palustris   Marsh Warbler         Dougie Preston   \n",
              "4    64685  Acrocephalus  palustris   Marsh Warbler         Dougie Preston   \n",
              "\n",
              "          country  latitude  longitute                     type  \\\n",
              "0          Poland   50.7932    15.4995       female, male, song   \n",
              "1          Poland   50.7932    15.4995  flight call, male, song   \n",
              "2     Netherlands   52.8176     6.4326               call, song   \n",
              "3  United Kingdom   60.3539    -1.2689                     Song   \n",
              "4  United Kingdom   60.3539    -1.2689                     Song   \n",
              "\n",
              "                                             license  \n",
              "0  http://creativecommons.org/licenses/by-nc-sa/3.0/  \n",
              "1  http://creativecommons.org/licenses/by-nc-sa/3.0/  \n",
              "2  http://creativecommons.org/licenses/by-nc-nd/2.5/  \n",
              "3  http://creativecommons.org/licenses/by-nc-nd/2.5/  \n",
              "4  http://creativecommons.org/licenses/by-nc-nd/2.5/  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-33b1e63e-e1e3-45cb-9e0a-d7d07e2d3920\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>genus</th>\n",
              "      <th>species</th>\n",
              "      <th>english_cname</th>\n",
              "      <th>who_provided_recording</th>\n",
              "      <th>country</th>\n",
              "      <th>latitude</th>\n",
              "      <th>longitute</th>\n",
              "      <th>type</th>\n",
              "      <th>license</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>132608</td>\n",
              "      <td>Acanthis</td>\n",
              "      <td>flammea</td>\n",
              "      <td>Common Redpoll</td>\n",
              "      <td>Jarek Matusiak</td>\n",
              "      <td>Poland</td>\n",
              "      <td>50.7932</td>\n",
              "      <td>15.4995</td>\n",
              "      <td>female, male, song</td>\n",
              "      <td>http://creativecommons.org/licenses/by-nc-sa/3.0/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>132611</td>\n",
              "      <td>Acanthis</td>\n",
              "      <td>flammea</td>\n",
              "      <td>Common Redpoll</td>\n",
              "      <td>Jarek Matusiak</td>\n",
              "      <td>Poland</td>\n",
              "      <td>50.7932</td>\n",
              "      <td>15.4995</td>\n",
              "      <td>flight call, male, song</td>\n",
              "      <td>http://creativecommons.org/licenses/by-nc-sa/3.0/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35068</td>\n",
              "      <td>Acanthis</td>\n",
              "      <td>flammea</td>\n",
              "      <td>Common Redpoll</td>\n",
              "      <td>Sander Bot</td>\n",
              "      <td>Netherlands</td>\n",
              "      <td>52.8176</td>\n",
              "      <td>6.4326</td>\n",
              "      <td>call, song</td>\n",
              "      <td>http://creativecommons.org/licenses/by-nc-nd/2.5/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>82715</td>\n",
              "      <td>Acrocephalus</td>\n",
              "      <td>palustris</td>\n",
              "      <td>Marsh Warbler</td>\n",
              "      <td>Dougie Preston</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>60.3539</td>\n",
              "      <td>-1.2689</td>\n",
              "      <td>Song</td>\n",
              "      <td>http://creativecommons.org/licenses/by-nc-nd/2.5/</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>64685</td>\n",
              "      <td>Acrocephalus</td>\n",
              "      <td>palustris</td>\n",
              "      <td>Marsh Warbler</td>\n",
              "      <td>Dougie Preston</td>\n",
              "      <td>United Kingdom</td>\n",
              "      <td>60.3539</td>\n",
              "      <td>-1.2689</td>\n",
              "      <td>Song</td>\n",
              "      <td>http://creativecommons.org/licenses/by-nc-nd/2.5/</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "      \n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-33b1e63e-e1e3-45cb-9e0a-d7d07e2d3920')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "      \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-33b1e63e-e1e3-45cb-9e0a-d7d07e2d3920 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-33b1e63e-e1e3-45cb-9e0a-d7d07e2d3920');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "  \n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "metadata = pd.read_csv(os.getcwd()+\"/drive/MyDrive/Data/birdsong_metadata.csv\")\n",
        "header = list(metadata.head())\n",
        "metadata.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtczJ816vkhg"
      },
      "source": [
        "#Working on data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1qNz0bbuyJ7"
      },
      "outputs": [],
      "source": [
        "# Get bird names\n",
        "bird_name = metadata['english_cname'].values\n",
        "u, f = np.unique(bird_name, return_counts=True)\n",
        "\n",
        "uniq_birds = list(u[4:10]) + list(u[12:15])\n",
        "# uniq_birds = list(u[0:10])\n",
        "data_train = []\n",
        "data_test = []\n",
        "y_train = []\n",
        "y_test = []\n",
        "bird_name_dict = {}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEvcgWp-uyXi"
      },
      "outputs": [],
      "source": [
        "for i in range(len(uniq_birds)) :\n",
        "    df = metadata[metadata['english_cname'] == uniq_birds[i]]\n",
        "    df = df['file_id'].values\n",
        "    df = df.tolist()\n",
        "    data_train.append(df[0])\n",
        "    y_train.append(i)\n",
        "    bird_name_dict[i] = uniq_birds[i]\n",
        "    data_test += df[1:]\n",
        "    y_test += [i] * (len(df) - 1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zpgjl0gXuyh1"
      },
      "outputs": [],
      "source": [
        "# Read audio files using librosa. Divide each audio clip into frames of 2 sec duration. They are more than 40 sec long clips. So, using frames\n",
        "# we will get a lot of data.\n",
        "frames_train = []\n",
        "frames_test = []\n",
        "frame_len = 22050*2 # equivalent of 2 seconds\n",
        "y_frames_train = []\n",
        "y_frames_test = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRCiwejvuylP",
        "outputId": "a4feb8e7-a9c5-4750-cd96-81fb0ca16fb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9/9 [00:14<00:00,  1.65s/it]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(len(data_train))) :\n",
        "\n",
        "    # Read audio\n",
        "    curr = data_train[i]\n",
        "    curr = \"/content/drive/MyDrive/Data/songs/songs/xc\" + str(curr) + \".flac\"\n",
        "    y, sr = librosa.load(curr)\n",
        "\n",
        "    # Normalize time series\n",
        "    y = ((y-np.amin(y))*2)/(np.amax(y) - np.amin(y)) - 1\n",
        "\n",
        "    # Remove silence from the audio\n",
        "    org_len = len(y)\n",
        "    intervals = librosa.effects.split(y, top_db= 15, ref= np.max)\n",
        "    intervals = intervals.tolist()\n",
        "    y = (y.flatten()).tolist()\n",
        "    nonsilent_y = []\n",
        "\n",
        "    for p,q in intervals :\n",
        "        nonsilent_y = nonsilent_y + y[p:q+1]\n",
        "\n",
        "    y = np.array(nonsilent_y)\n",
        "    final_len = len(y)\n",
        "    sil = org_len - final_len\n",
        "\n",
        "\n",
        "    # Divide audio into frames\n",
        "    start = 0\n",
        "    end = frame_len\n",
        "    for j in range(0, len(y), int(frame_len*0.5)) :\n",
        "\n",
        "        frame = y[j:j+frame_len]\n",
        "        if len(frame) < frame_len :\n",
        "            frame = frame.tolist() + [0]* (frame_len-len(frame))\n",
        "        frame = np.array(frame)\n",
        "        S = np.abs(librosa.stft(frame, n_fft=512))\n",
        "        freqs = librosa.fft_frequencies(sr=sr, n_fft=512)\n",
        "        upper = ([x for x in range(len(freqs)) if freqs[x] >= 8000])[0]\n",
        "        lower = ([x for x in range(len(freqs)) if freqs[x] <= 1000])[-1]\n",
        "\n",
        "        freqs = freqs[lower:upper]\n",
        "        S = S[lower:upper,:]\n",
        "        if S.shape != (163, 345) :\n",
        "            print(S.shape)\n",
        "        assert S.shape == (163, 345)\n",
        "\n",
        "        frames_train.append(S)\n",
        "        y_frames_train.append(y_train[i])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QNYVcjLAawP"
      },
      "source": [
        "##Read testing data and split into frames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USZ1Tg6JuypZ",
        "outputId": "3a7741a2-4585-4c18-955d-7dce02ecb02c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 18/18 [00:14<00:00,  1.21it/s]\n"
          ]
        }
      ],
      "source": [
        "for i in tqdm(range(len(data_test))) :\n",
        "    # Read audio\n",
        "    curr = data_test[i]\n",
        "    curr = \"/content/drive/MyDrive/Data/songs/songs/xc\" + str(curr) + \".flac\"\n",
        "    y, sr = librosa.load(curr)\n",
        "    dur = librosa.get_duration(y=y, sr=sr)\n",
        "\n",
        "    # Normalize time series\n",
        "    y = ((y-np.amin(y))*2)/(np.amax(y) - np.amin(y)) - 1\n",
        "\n",
        "    # Remove silence from the audio\n",
        "    org_len = len(y)\n",
        "    intervals = librosa.effects.split(y, top_db= 15, ref= np.max)\n",
        "    intervals = intervals.tolist()\n",
        "    y = (y.flatten()).tolist()\n",
        "    nonsilent_y = []\n",
        "\n",
        "    for p,q in intervals :\n",
        "        nonsilent_y = nonsilent_y + y[p:q+1]\n",
        "\n",
        "    y = np.array(nonsilent_y)\n",
        "    final_len = len(y)\n",
        "    sil = org_len - final_len\n",
        "\n",
        "\n",
        "    dur = librosa.get_duration(y=y, sr=sr)\n",
        "    start = 0\n",
        "    end = frame_len\n",
        "    for j in range(0, len(y), int(frame_len*0.5)) :\n",
        "        frame = y[j:j+frame_len]\n",
        "        if len(frame) < frame_len :\n",
        "            frame = frame.tolist() + [0]* (frame_len-len(frame))\n",
        "        frame = np.array(frame)\n",
        "\n",
        "        S = np.abs(librosa.stft(frame, n_fft=512))\n",
        "        freqs = librosa.fft_frequencies(sr=sr, n_fft=512)\n",
        "        upper = ([x for x in range(len(freqs)) if freqs[x] >= 8000])[0]\n",
        "        lower = ([x for x in range(len(freqs)) if freqs[x] <= 1000])[-1]\n",
        "\n",
        "        freqs = freqs[lower:upper]\n",
        "        S = S[lower:upper,:]\n",
        "        assert S.shape == (163, 345)\n",
        "\n",
        "        frames_test.append(S)\n",
        "        y_frames_test.append(y_test[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLjr-Ni5uyrb",
        "outputId": "4f9ac983-d550-4236-c41b-87eec4a848ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples :  341 341 (array([0, 1, 2, 3, 4, 5, 6, 7, 8]), array([ 21,   6,  12,  52,  25, 139,  20,   7,  59]))\n",
            "Testing samples :  469 469 (array([0, 1, 2, 3, 4, 5, 6, 7, 8]), array([ 19,  74,  44,   9,  21,  12,  47, 183,  60]))\n"
          ]
        }
      ],
      "source": [
        "print(\"Training samples : \",  len(frames_train), len(y_frames_train), np.unique(y_frames_train, return_counts= True))\n",
        "print(\"Testing samples : \",  len(frames_test), len(y_frames_test), np.unique(y_frames_test, return_counts= True))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9nAcgsTB59u"
      },
      "source": [
        "## Convert all data to nd array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFWuOrnPBrVn"
      },
      "outputs": [],
      "source": [
        "y_frames_train = np.array(y_frames_train)\n",
        "y_frames_test = np.array(y_frames_test)\n",
        "\n",
        "r,c = frames_train[0].shape\n",
        "frames_train = np.array(frames_train)\n",
        "frames_train = frames_train.reshape((len(frames_train), r, c))\n",
        "\n",
        "frames_test = np.array(frames_test)\n",
        "frames_test = frames_test.reshape((len(frames_test), r, c))\n",
        "\n",
        "dataX = np.concatenate((frames_train, frames_test), axis=0)\n",
        "datay = np.concatenate((y_frames_train, y_frames_test), axis=0)\n",
        "\n",
        "frames_train, frames_test, y_frames_train, y_frames_test = train_test_split(dataX, datay, test_size=0.6)  #####################"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wgK7EsXXBrcr"
      },
      "outputs": [],
      "source": [
        "f = open(os.getcwd() + \"/training_frames1.pkl\", 'wb')\n",
        "pickle.dump([frames_train, y_frames_train], f)\n",
        "f.close()\n",
        "\n",
        "f = open(os.getcwd() + \"/testing_frames1.pkl\", 'wb')\n",
        "pickle.dump([frames_test, y_frames_test], f)\n",
        "f.close()\n",
        "\n",
        "\n",
        "# Read training and testing data from the pickle file\n",
        "f = open(os.getcwd() + \"/training_frames1.pkl\", 'rb')\n",
        "frames_train, y_frames_train = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open(os.getcwd() + \"/testing_frames1.pkl\", 'rb')\n",
        "frames_test, y_frames_test = pickle.load(f)\n",
        "f.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BP9tzMMCoyV"
      },
      "source": [
        "### Read training and testing data from the pickle file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EvlpM-2tCokw"
      },
      "outputs": [],
      "source": [
        "f = open(os.getcwd() + \"/training_frames1.pkl\", 'rb')\n",
        "frames_train, y_frames_train = pickle.load(f)\n",
        "f.close()\n",
        "\n",
        "f = open(os.getcwd() + \"/testing_frames1.pkl\", 'rb')\n",
        "frames_test, y_frames_test = pickle.load(f)\n",
        "f.close()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ByAe7V2CzaB"
      },
      "source": [
        "### Standardize the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mdhRCDpFCzRu",
        "outputId": "ac6f7b85-5277-4965-8a43-6c82e19945f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples :  (324, 163, 345) 324 (array([0, 1, 2, 3, 4, 5, 6, 7, 8]), array([17, 33, 19, 27, 18, 64, 26, 68, 52]))\n",
            "Testing samples :  (486, 163, 345) 486 (array([0, 1, 2, 3, 4, 5, 6, 7, 8]), array([ 23,  47,  37,  34,  28,  87,  41, 122,  67]))\n"
          ]
        }
      ],
      "source": [
        "\n",
        "mu = frames_train.mean()\n",
        "std = frames_train.std()\n",
        "frames_train = (frames_train-mu)/std\n",
        "frames_test = (frames_test-mu)/std\n",
        "\n",
        "print(\"Training samples : \",  frames_train.shape, len(y_frames_train), np.unique(y_frames_train, return_counts= True))\n",
        "print(\"Testing samples : \", frames_test.shape, len(y_frames_test), np.unique(y_frames_test, return_counts= True))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5twmbSR3Dtkc"
      },
      "outputs": [],
      "source": [
        "# There are imbalanced classes. Repeat the data so that all classes have same number of samples.\n",
        "u, f = np.unique(y_frames_train, return_counts= True)\n",
        "frames_train1 = []\n",
        "y_frames_train1 = []\n",
        "maximum = max(f)\n",
        "count = 0\n",
        "for i in u :\n",
        "    ind, = np.where(y_frames_train == i)\n",
        "    ind = ind.tolist()\n",
        "    while len(ind) < maximum :\n",
        "        ind = ind + ind\n",
        "    ind = ind[:maximum]\n",
        "    temp = frames_train[ind]\n",
        "    if count == 0 :\n",
        "        frames_train1 = temp\n",
        "        count += 1\n",
        "    else :\n",
        "        frames_train1 = np.concatenate((frames_train1, temp), axis= 0)\n",
        "\n",
        "    y_frames_train1 += [i] * maximum\n",
        "\n",
        "y_frames_train1 = np.array(y_frames_train1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa0ly21QFDlU"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ZLTtca3Dz6J"
      },
      "outputs": [],
      "source": [
        "import os, sys, matplotlib.pyplot as plt, numpy as np, itertools, math\n",
        "from random import seed\n",
        "from random import random, randint\n",
        "from scipy.spatial import distance\n",
        "from  tqdm import tqdm\n",
        "import random\n",
        "import warnings\n",
        "from math import factorial\n",
        "\n",
        "def generate_positive_pairs(X, y, rand_samples, pair_len) :\n",
        "\n",
        "    # Shape of features\n",
        "    row, col = X.shape[0], X.shape[1]\n",
        "\n",
        "    # Get unique elements of y array along with their frequencies\n",
        "    uniq, freq = np.unique(y, return_counts=True)\n",
        "\n",
        "    anchor = []\n",
        "    pos = []\n",
        "    count = 0\n",
        "\n",
        "    # Traverse through each class and select random samples\n",
        "    for x, f in zip(uniq, freq) :\n",
        "\n",
        "        # Select indices of a certian class label\n",
        "        ind, = np.where(y == x)\n",
        "        ind = list(ind)\n",
        "\n",
        "        # Select random samples indices. If number of samples required are more than frequency of class, then select all samples\n",
        "        if rand_samples <= f and rand_samples != -1:\n",
        "            random_indices = random.sample(ind, rand_samples)\n",
        "        elif rand_samples == -1 :\n",
        "            random_indices = ind\n",
        "        else :\n",
        "            warnings.warn(\"ValueError ! 'samples' required are more than number of elements in class. So, all elements are selected.\")\n",
        "            random_indices = random.sample(ind, f)\n",
        "\n",
        "        # Generate positive pairs\n",
        "        pairs = list(itertools.combinations(random_indices, 2))\n",
        "\n",
        "        if len(pairs) >= pair_len :\n",
        "            pairs = list(pairs)[:pair_len]\n",
        "\n",
        "        # print(len(pairs))\n",
        "\n",
        "        # Get features associated with those indices\n",
        "        anchor += [X[i] for i, _ in pairs]\n",
        "        pos += [X[i] for _, i in pairs]\n",
        "\n",
        "    # Convert features to numpy matrix\n",
        "    anchor = np.array(anchor)\n",
        "    a = (len(anchor),)\n",
        "    b = tuple(X[0].shape)\n",
        "    anchor = anchor.reshape(a+b)\n",
        "\n",
        "    a = (len(anchor),)\n",
        "\n",
        "    pos = np.array(pos)\n",
        "    pos = pos.reshape(a+b)\n",
        "\n",
        "    # print(positive_extra[0].shape)\n",
        "\n",
        "    return anchor, pos, uniq, freq\n",
        "\n",
        "\n",
        "def generate_negative_pairs(X, y, uniq, freq, rand_samples, pair_len) :\n",
        "\n",
        "    # Shape of features\n",
        "    row, col = X.shape[0], X.shape[1]\n",
        "\n",
        "    # Get unique elements of y array along with their frequencies\n",
        "    # uniq, _ = np.unique(y, return_counts=True)\n",
        "    indices = []\n",
        "\n",
        "    # Traverse through each class and select random samples\n",
        "    for x, f in zip(uniq, freq) :\n",
        "\n",
        "        # Select indices of a certian class label\n",
        "        ind, = np.where(y == x)\n",
        "        ind = list(ind)\n",
        "\n",
        "        # Select random samples indices. If number of samples required are more than frequency of class, then select all samples\n",
        "        if rand_samples <= f and rand_samples != -1:\n",
        "            random_indices = random.sample(ind, rand_samples)\n",
        "        elif rand_samples == -1 :\n",
        "            random_indices = ind\n",
        "        else :\n",
        "            warnings.warn(\"ValueError ! 'samples' required are more than number of elements in class. So, all elements are selected.\")\n",
        "            random_indices = random.sample(ind, f)\n",
        "\n",
        "        # Get features associated with those indices\n",
        "        indices.append(random_indices)\n",
        "        # print(len(random_indices))\n",
        "\n",
        "    neg = []\n",
        "\n",
        "    # Generate negative pairs\n",
        "    for i in range(len(uniq)) :\n",
        "\n",
        "        # Generate pair of a class with every other class\n",
        "        for j in range(len(uniq)) :\n",
        "\n",
        "            if i == j :\n",
        "                continue\n",
        "\n",
        "\n",
        "            curr = indices[j]\n",
        "            num = math.ceil(pair_len/(len(uniq)-1))\n",
        "            while len(curr) < num :\n",
        "                curr += indices[j]\n",
        "\n",
        "            indices1 = random.sample(curr, num)\n",
        "            indices1 = indices1[:pair_len]\n",
        "            # Get features associated with those indices\n",
        "            neg += [X[p] for p in indices1]\n",
        "\n",
        "\n",
        "    # Convert features to numpy matrix\n",
        "    neg = np.array(neg)\n",
        "    a = (len(neg),)\n",
        "    b = tuple(X[0].shape)\n",
        "\n",
        "    neg = neg.reshape(a+b)\n",
        "\n",
        "\n",
        "    return neg\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Computed number of combinations nCr\n",
        "def calculate_combinations(n, r):\n",
        "    return factorial(n) // factorial(r) // factorial(n-r)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Generate positive and negative pairs. This function selects samples in such a way that nmber fo apositive pairs equals number\n",
        "of negative pairs. Only exception is when the numbers of samples are less than total combinations of all classes.\n",
        "Parameters:\n",
        "\n",
        "    INPUT\n",
        "                   X : Input features, Type: nd array\n",
        "                   y : class labels, Type: 1d numpy array\n",
        "             rand_samples : Number of random samples taken from each class, Type: integer. By default it selects all samples\n",
        "            pos_pair_size : Number of positive random pairs from each class, Type: integer. By default it selects all pairs\n",
        "\n",
        "    OUTPUT\n",
        "            anchor and pos are positive pairs of features.\n",
        "            neg and neg_X2 are negative pairs of features.\n",
        "\n",
        "'''\n",
        "\n",
        "def generate_pairs(X, y, rand_samples, pos_pair_size=-1, extra_data=[]) :\n",
        "\n",
        "\n",
        "    # print(\"Input \", len(extra_data))\n",
        "    uniq, f = np.unique(y, return_counts= True)\n",
        "\n",
        "    N = len(uniq)\n",
        "    pair_neg = calculate_combinations(N, 2)\n",
        "    pair_pos = calculate_combinations(min(f), 2)\n",
        "\n",
        "    pos_pair_size = min(pos_pair_size, pair_pos )\n",
        "\n",
        "    if pos_pair_size == -1 :\n",
        "        if rand_samples == -1 :\n",
        "            # pos_pair_size = calculate_combinations(int(len(y)/N), 2)\n",
        "            pos_pair_size = calculate_combinations(int(min(f)), 2)\n",
        "        else :\n",
        "            # pos_pair_size = min(calculate_combinations(rand_samples, 2), int(len(y)/N) )\n",
        "            pos_pair_size = min(calculate_combinations(rand_samples, 2), pair_pos )\n",
        "\n",
        "    pos_pair_size = int(pos_pair_size)\n",
        "    # print(\"pos pair size \", pos_pair_size)\n",
        "    for i in range(pos_pair_size, 0, -1):\n",
        "        if ((N/ pair_neg) * i).is_integer() :\n",
        "            break\n",
        "\n",
        "    neg_samples = int((N/ pair_neg) * i)\n",
        "    pos_samples = i\n",
        "\n",
        "    if ((N/ pair_neg) * i).is_integer() is False :\n",
        "        warnings.warn(\"Number of samples per class are less than total combinations of all classes. 1 sample will be selected from each negative pair. \")\n",
        "        neg_samples = 1\n",
        "\n",
        "    # print(N, pair_neg, neg_samples, i)\n",
        "    # print(pair_neg, neg_samples, pos_pair_size, i)\n",
        "    # print(pair_neg * neg_samples, pos_pair_size * i)\n",
        "    # sys.exit(1)\n",
        "\n",
        "    anchor, pos, uniq, freq = generate_positive_pairs(X, y, rand_samples= rand_samples, pair_len=pos_samples)\n",
        "    neg = generate_negative_pairs(X, y, uniq, freq, rand_samples= rand_samples, pair_len=pos_samples)\n",
        "\n",
        "    return anchor, pos, neg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uOTpJE4mFJ3"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "1E8XzAc_FMIs",
        "outputId": "83a355ab-c537-4af5-911f-04ed46146bc8"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-7188b6ec4963>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Make pairs for siamese network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0manchor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_pairs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframes_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_frames_train1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_samples\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_pair_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m600\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0manchor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'frames_train1' is not defined"
          ]
        }
      ],
      "source": [
        "# Make pairs for siamese network\n",
        "anchor, pos, neg = generate_pairs(frames_train1, y_frames_train1, rand_samples= -1, pos_pair_size=600)\n",
        "\n",
        "anchor = anchor.astype(np.float16)\n",
        "pos = pos.astype(np.float16)\n",
        "neg = neg.astype(np.float16)\n",
        "\n",
        "np.savez_compressed(os.getcwd()+'/training_siamese_frames', a=anchor, b= pos, c= neg)\n",
        "\n",
        "data = np.load(os.getcwd()+'/training_siamese_frames.npz')\n",
        "anchor = data['a']\n",
        "pos = data['b']\n",
        "neg = data['c']\n",
        "\n",
        "\n",
        "print(\"Siamese pairs \", anchor.shape, pos.shape, neg.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbld7h78h3Wm"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import libraries\n",
        "import os, sys, cv2, matplotlib.pyplot as plt, numpy as np, shutil, itertools, pickle, pandas as pd, seaborn as sn, math, time\n",
        "from random import seed, random, randint\n",
        "from scipy.spatial import distance\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from keras import backend as K\n",
        "from keras.models import Model, load_model, Sequential\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.layers import Input, Dense, Embedding, AveragePooling1D, dot, UpSampling2D, concatenate, BatchNormalization, LSTM, Multiply, Conv2D, MaxPool2D, Add, dot, GlobalMaxPool1D, Dropout, Masking, Activation, MaxPool1D, Conv1D, Flatten, TimeDistributed, Lambda\n",
        "from keras.regularizers import l2\n",
        "# from keras.utils.vis_utils import plot_model\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.preprocessing import normalize\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "\n",
        "import soundfile as sf\n",
        "\n",
        "emb_size = 32\n",
        "alpha = 0.8\n",
        "\n",
        "\n",
        "# Triplet loss\n",
        "def triplet_loss(y_true, y_pred):\n",
        "\n",
        "    anchor, positive, negative = y_pred[:,:emb_size], y_pred[:,emb_size:2*emb_size], y_pred[:,2*emb_size:]\n",
        "    distance1 = tf.reduce_mean(tf.square(anchor - positive), axis=1)\n",
        "    distance2 = tf.reduce_mean(tf.square(anchor - negative), axis=1)\n",
        "    loss = tf.reduce_mean(tf.maximum(distance1 - distance2 + alpha, 0))\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "# Build Model\n",
        "\n",
        "def get_model(r,c) :\n",
        "\n",
        "    # hyper-parameters\n",
        "    n_filters = 64\n",
        "    filter_width = 3\n",
        "    dilation_rates = [2**i for i in range(8)]\n",
        "\n",
        "    history_seq = Input(shape=(r, c))\n",
        "    x = history_seq\n",
        "\n",
        "    skips = []\n",
        "    count = 0\n",
        "    for dilation_rate in dilation_rates:\n",
        "        x = Conv1D(filters=n_filters,\n",
        "                    kernel_size=filter_width,\n",
        "                    padding='causal',\n",
        "                    dilation_rate=dilation_rate, activation='relu', name=\"conv1d_dilation_\"+str(dilation_rate))(x)\n",
        "\n",
        "        x = BatchNormalization()(x)\n",
        "\n",
        "\n",
        "    out = Conv1D(32, 16, padding='same')(x)\n",
        "    out = BatchNormalization()(out)\n",
        "    out = Activation('tanh')(out)\n",
        "    out = GlobalMaxPool1D()(out)\n",
        "\n",
        "    model = Model(history_seq, out)\n",
        "    model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "    input1 = Input((r,c), name=\"Anchor Input\")\n",
        "    input2 = Input((r,c), name=\"Positive Input\")\n",
        "    input3 = Input((r,c), name=\"Negative Input\")\n",
        "\n",
        "    anchor = model(input1)\n",
        "    positive = model(input2)\n",
        "    negative = model(input3)\n",
        "\n",
        "\n",
        "    concat = concatenate([anchor, positive, negative], axis=1)\n",
        "\n",
        "    siamese = Model([input1, input2, input3], concat)\n",
        "\n",
        "\n",
        "    siamese.compile(optimizer='adam', loss=triplet_loss)\n",
        "\n",
        "    print(siamese.summary())\n",
        "\n",
        "    return model, siamese\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57nWyJxxFf0B"
      },
      "outputs": [],
      "source": [
        "_,r,c = anchor.shape\n",
        "encoder, model = get_model(c,r)\n",
        "\n",
        "anchor = pos.transpose(0, 2, 1)\n",
        "pos = pos.transpose(0, 2, 1)\n",
        "neg = neg.transpose(0, 2, 1)\n",
        "\n",
        "y = np.ones((len(anchor), 32*3))\n",
        "\n",
        "# Fit model\n",
        "mc = ModelCheckpoint(os.getcwd()+'/model_checkpoint.h5',\n",
        "                            save_weights_only=False, save_freq=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWiFuG7dix5W"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit([anchor, pos, neg], y, epochs= 30, callbacks= [mc], batch_size= 256, verbose= 1)\n",
        "model.save(os.getcwd() + \"/siamese.h5\")\n",
        "encoder.save(os.getcwd() + \"/encoder.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ijmRNVQjY0n"
      },
      "outputs": [],
      "source": [
        "# Load the model\n",
        "model = load_model(os.getcwd() + \"/siamese.h5\", compile= False)\n",
        "encoder = load_model(os.getcwd() + \"/encoder.h5\", compile= False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0aONfhNjZbD"
      },
      "outputs": [],
      "source": [
        "# Create the confusion and similarity matrix\n",
        "from scipy import spatial\n",
        "\n",
        "frames_test = frames_test.transpose(0,2,1)\n",
        "frames_train1 = frames_train1.transpose(0,2,1)\n",
        "\n",
        "\n",
        "sim_mat = np.zeros((len(frames_test), len(frames_test)))\n",
        "ind = np.arange(0, len(frames_test), 1)\n",
        "ind = [x for _,x in sorted(zip(y_frames_test, ind))]\n",
        "frames_test = frames_test[ind]\n",
        "y_frames_test = y_frames_test[ind]\n",
        "\n",
        "encoded = encoder.predict(frames_test)\n",
        "\n",
        "pred = []\n",
        "\n",
        "for i in tqdm(range(len(frames_test))) :\n",
        "\n",
        "    curr = frames_test[i:i+1]\n",
        "    sim = encoder.predict(curr)\n",
        "    sim = [1 - spatial.distance.cosine(sim[0], encoded[x]) for x in range(len(encoded))]\n",
        "    sim = np.array(sim)\n",
        "\n",
        "    sim[sim<0] = 0\n",
        "    ind = np.copy(y_frames_test)\n",
        "\n",
        "    ind = [x for _,x in sorted(zip(sim, ind))]\n",
        "    ind = ind[::-1]\n",
        "    ind = ind[:21]\n",
        "    u, f = np.unique(ind, return_counts= True)\n",
        "    best = u[np.argmax(f)]\n",
        "    pred.append(best)\n",
        "    sim_mat[i] = sim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt8QZCl4jf1C"
      },
      "outputs": [],
      "source": [
        "conf_mat = confusion_matrix(y_frames_test, pred, normalize= 'true')\n",
        "print(\"Accuracy on testset : \", np.trace(conf_mat)/np.sum(conf_mat))\n",
        "\n",
        "u = np.unique(y_frames_test)\n",
        "\n",
        "\n",
        "# Plot confusion matrix\n",
        "conf_mat = pd.DataFrame(conf_mat, columns= [bird_name_dict[x] for x in u], index= [bird_name_dict[x] for x in u])\n",
        "plt.figure(figsize = (20,15))\n",
        "sn.heatmap(conf_mat, annot=True, annot_kws={\"size\": 10}, cmap='jet')\n",
        "plt.tick_params(labelsize=8)\n",
        "plt.xticks(rotation= 60)\n",
        "plt.title(\"Bird Song classification\")\n",
        "plt.show()\n",
        "plt.savefig(os.getcwd()+\"/ConfusionMatrix_test.png\")\n",
        "plt.close()\n",
        "\n",
        "\n",
        "# Plot similarity matrix\n",
        "sim_mat = pd.DataFrame(sim_mat, columns= [bird_name_dict[x] for x in y_frames_test], index= [bird_name_dict[x] for x in y_frames_test])\n",
        "plt.figure(figsize = (20,15))\n",
        "sn.heatmap(sim_mat, annot=False, annot_kws={\"size\": 12}, cmap='viridis')\n",
        "plt.tick_params(labelsize=10)\n",
        "plt.xticks(rotation= 90)\n",
        "plt.title(\"Bird Song classification\")\n",
        "plt.show()\n",
        "plt.savefig(os.getcwd()+\"/SimilarityMatrix_test.png\")\n",
        "plt.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}